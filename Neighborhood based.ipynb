{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Based Recommender Systems\n",
    "Here we implement a user-based recommender system on the MovieLens 100k Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "\n",
    "# numbers of users and items from u.info\n",
    "\n",
    "ITEMS = 1682\n",
    "USERS = 943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## u1 data set\n",
    "Here we work with the u1 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads data from file and writes it to target, a numpy array\n",
    "def read_data(file, target):\n",
    "    with open(file) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            user, item, rating, _ = line.split()\n",
    "            target[int(user)-1][int(item)-1] = int(rating)\n",
    "            line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the ratings in u1.base\n",
    "\n",
    "u1_train_data = np.zeros((USERS, ITEMS))\n",
    "\n",
    "read_data(\".\\\\ml-100k\\\\u1.base\", u1_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average rating for each user\n",
    "\n",
    "averages = [np.average(user, weights=user.astype(bool)) for user in u1_train_data]\n",
    "\n",
    "# Find which items are rated by each user and which users rated each item\n",
    "rated_items = [{k for k in range(ITEMS) if u1_train_data[i][k] > 0} for i in range(USERS)]\n",
    "rated_users = [{k for k in range(USERS) if u1_train_data[k][i] > 0} for i in range(ITEMS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that most of the prep work is done, it's time to calculate the matrix of Pearson correlation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implements the Pearson metric as found in equation (2.2)\n",
    "\n",
    "def pearson(user1, user2):\n",
    "    intersection = rated_items[user1].intersection(rated_items[user2])\n",
    "    if len(intersection) <= 1:\n",
    "        return 0\n",
    "\n",
    "    bottom1 = math.sqrt( sum([(u1_train_data[user1][k] - averages[user1]) ** 2 for k in intersection]))\n",
    "    bottom2 = math.sqrt( sum([(u1_train_data[user2][k] - averages[user2]) ** 2 for k in intersection]))\n",
    "\n",
    "    if bottom1 * bottom2 == 0:\n",
    "        return 0\n",
    "        \n",
    "    top = sum([(u1_train_data[user1][k] - averages[user1]) * (u1_train_data[user2][k] - averages[user2]) for k in intersection])\n",
    "\n",
    "    return top / (bottom1 * bottom2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know if this is the way to go about this.\n",
    "# It takes a long time to run. However, I think it'set\n",
    "# necessary because we'll have to calculate these values\n",
    "# sooner or later anyways.\n",
    "\n",
    "pearson_matrix = np.zeros((USERS,USERS))\n",
    "for user1 in range(USERS):\n",
    "    # since the matrix is symmetric, we can save time by only calculating half the values\n",
    "    for user2 in range(USERS):\n",
    "        if user1 == user2:\n",
    "            pearson_matrix[user1][user2] = 1\n",
    "            continue\n",
    "        pm = pearson(user1,user2) \n",
    "        if pm > 1:\n",
    "            pm = 1\n",
    "        pearson_matrix[user1][user2] = pm\n",
    "        pearson_matrix[user1][user2] = pm\n",
    "np.savetxt(\"pearsonmatrix.csv\", pearson_matrix, delimiter=', ', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the users who rated item, return the k with highest pearson correlation value with a specified user\n",
    "\n",
    "def k_closest(user, item, k):\n",
    "    pearson_sorted = sorted((i for i in range(USERS) if i in rated_users[item]), key=lambda x: pearson_matrix[user][x])[-k:]\n",
    "    return pearson_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement r-hat as in equation 2.4\n",
    "\n",
    "def r_hat(user, item):\n",
    "    K_closest_users = k_closest(user, item, K)\n",
    "    # Come up with something to do if the k_closest is empty\n",
    "    if len(K_closest_users) == 0:\n",
    "        raise ZeroDivisionError\n",
    "    top = sum(pearson_matrix[user][user2] * (u1_train_data[user2][item] - averages[user2]) for user2 in K_closest_users)\n",
    "    bot = sum(abs(pearson_matrix[user][user2]) for user2 in K_closest_users)\n",
    "\n",
    "    return averages[user] + top/bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the ratings in u1.test\n",
    "u1_test_data = np.zeros((USERS,ITEMS))\n",
    "read_data(\".\\\\ml-100k\\\\u1.test\", u1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for each user-item pair in the test data.\n",
    "testing_size = 0\n",
    "error_count = 0\n",
    "u1_pred = np.zeros((USERS,ITEMS))\n",
    "for user in range(USERS):\n",
    "    for item in range(ITEMS):\n",
    "        if u1_test_data[user][item] == 0:\n",
    "            continue\n",
    "        try:\n",
    "            pred_val = r_hat(user, item)\n",
    "            u1_pred[user][item] = pred_val\n",
    "            testing_size += 1\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "            #print(user, item)\n",
    "            # error_count += 1\n",
    "#         if pred_val > 5 or pred_val < 0:\n",
    "#             print(user, item, pred_val)\n",
    "# print(testing_size, error_count)\n",
    "# np.savetxt(\"pred.csv\", u1_pred, delimiter=', ', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0239996622010517\n"
     ]
    }
   ],
   "source": [
    "# RMSE as found in equation 7.5\n",
    "\n",
    "count = 0\n",
    "squared_error = 0\n",
    "\n",
    "for user in range(USERS):\n",
    "    for item in range(ITEMS):\n",
    "        if u1_pred[user][item] == 0:\n",
    "            continue\n",
    "        squared_error += (u1_pred[user][item] - u1_test_data[user][item]) ** 2\n",
    "        count += 1\n",
    "\n",
    "RMSE = math.sqrt(squared_error / count)\n",
    "print(RMSE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b1a5b2f53fe8d0bcd4ac39533e586bc42b57972f340950c5b9dd959554a56a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MLLA': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
