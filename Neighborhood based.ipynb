{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Based Recommender Systems\n",
    "Here we implement a user-based recommender system on the MovieLens 100k Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers of users and items from u.info\n",
    "# Hi Jason - Olivia\n",
    "ITEMS = 1682\n",
    "USERS = 943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## u1 data set\n",
    "Here we work with the u1 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads data from file and writes it to target, a numpy array\n",
    "def read_data(file, target):\n",
    "    with open(file) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            user, item, rating, _ = line.split()\n",
    "            target[int(user)-1][int(item)-1] = int(rating)\n",
    "            line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the ratings in u1.base\n",
    "\n",
    "u1_train_data = np.zeros((USERS, ITEMS))\n",
    "\n",
    "read_data(\".\\\\ml-100k\\\\u1.base\", u1_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average rating for each user\n",
    "\n",
    "averages = [np.average(user, weights=user.astype(bool)) for user in u1_train_data]\n",
    "\n",
    "# Find which items are rated by each user and which users rated each item\n",
    "rated_items = [{k for k in range(ITEMS) if u1_train_data[i][k] > 0} for i in range(USERS)]\n",
    "rated_users = [{k for k in range(USERS) if u1_train_data[k][i] > 0} for i in range(ITEMS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that most of the prep work is done, it's time to calculate the matrix of Pearson correlation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implements the Pearson metric as found in equation (2.2)\n",
    "\n",
    "def pearson(user1, user2):\n",
    "    intersection = rated_items[user1].intersection(rated_items[user2])\n",
    "    if len(intersection) <= 1:\n",
    "        return 0\n",
    "\n",
    "    bottom1 = math.sqrt( sum([(u1_train_data[user1][k] - averages[user1]) ** 2 for k in intersection]))\n",
    "    bottom2 = math.sqrt( sum([(u1_train_data[user2][k] - averages[user2]) ** 2 for k in intersection]))\n",
    "\n",
    "    if bottom1 * bottom2 == 0:\n",
    "        return 0\n",
    "        \n",
    "    top = sum([(u1_train_data[user1][k] - averages[user1]) * (u1_train_data[user2][k] - averages[user2]) for k in intersection])\n",
    "\n",
    "    return top / (bottom1 * bottom2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know if this is the way to go about this.\n",
    "# It takes a long time to run. However, I think it'set\n",
    "# necessary because we'll have to calculate these values\n",
    "# sooner or later anyways.\n",
    "\n",
    "pearson_matrix = np.zeros((USERS,USERS))\n",
    "for user1 in range(USERS):\n",
    "    # since the matrix is symmetric, we can save time by only calculating half the values\n",
    "    for user2 in range(USERS):\n",
    "        if user1 == user2:\n",
    "            pearson_matrix[user1][user2] = 1\n",
    "            continue\n",
    "        pm = pearson(user1,user2) \n",
    "        if pm > 1:\n",
    "            pm = 1\n",
    "        pearson_matrix[user1][user2] = pm\n",
    "        pearson_matrix[user1][user2] = pm\n",
    "np.savetxt(\"pearsonmatrix.csv\", pearson_matrix, delimiter=', ', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the users who rated item, return the k with highest pearson correlation value with a specified user\n",
    "\n",
    "def k_closest(user, item, k):\n",
    "    pearson_sorted = sorted((i for i in range(USERS) if i in rated_users[item]), key=lambda x: pearson_matrix[user][x])[-k:]\n",
    "    return pearson_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement r-hat as in equation 2.4\n",
    "\n",
    "def r_hat(user, item, K):\n",
    "    K_closest_users = k_closest(user, item, K)\n",
    "    # Come up with something to do if the k_closest is empty\n",
    "    if len(K_closest_users) == 0:\n",
    "        raise ZeroDivisionError\n",
    "    top = sum(pearson_matrix[user][user2] * (u1_train_data[user2][item] - averages[user2]) for user2 in K_closest_users)\n",
    "    bot = sum(abs(pearson_matrix[user][user2]) for user2 in K_closest_users)\n",
    "\n",
    "    return averages[user] + top/bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the ratings in u1.test\n",
    "u1_test_data = np.zeros((USERS,ITEMS))\n",
    "read_data(\".\\\\ml-100k\\\\u1.test\", u1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5566819767721967\n"
     ]
    }
   ],
   "source": [
    "# RMSE as found in equation 7.5\n",
    "# Calculated using the average ratings of each user as a baseline\n",
    "\n",
    "squared_error_avg = 0\n",
    "count = 0\n",
    "\n",
    "for user in range(USERS):\n",
    "    for item in range(ITEMS):\n",
    "        if u1_train_data[user][item] == 0:\n",
    "            continue\n",
    "        squared_error_avg += (averages[user] - u1_test_data[user][item]) ** 2\n",
    "        count += 1\n",
    "\n",
    "RMSE_avg = math.sqrt(squared_error_avg / count)\n",
    "print(RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def user_kendall_coef(user):\n",
    "    credit = 0\n",
    "    test_items = {k for k in range(ITEMS) if u1_test_data[user][k] > 0}\n",
    "\n",
    "    if len(test_items) <= 1:\n",
    "        raise ZeroDivisionError\n",
    "\n",
    "    for item1, item2 in combinations(test_items, 2):\n",
    "        val = (u1_test_data[user][item1] - u1_test_data[user][item2]) * (u1_pred[user][item1] - u1_pred[user][item2])\n",
    "        if val > 0:\n",
    "            credit += 1\n",
    "        elif val < 0:\n",
    "            credit -= 1\n",
    "    \n",
    "    return credit / (len(test_items) * (len(test_items) - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.1471512227418752 0.14975463921548315\n",
      "3 1.0832787727110045 0.17233290808699941\n",
      "4 1.0454038909248713 0.19277338469043617\n",
      "5 1.0239996622010517 0.20134443328930837\n",
      "6 1.008972984940028 0.2104509200040167\n",
      "7 0.9999452805411727 0.2190403578107192\n",
      "8 0.9927131264171871 0.21913688307398607\n",
      "9 0.9883334713150379 0.2261951630381763\n",
      "10 0.9840243851860677 0.22588468894444083\n",
      "11 0.9808089208383695 0.22726524222891462\n",
      "12 0.977973031548584 0.22707379750826054\n",
      "13 0.9751579727472001 0.22948748301322777\n",
      "14 0.9735193959369345 0.23074415362878617\n",
      "15 0.9716044487861084 0.23744638171501078\n",
      "16 0.9695178634572917 0.23854863699821183\n",
      "17 0.9685811441261292 0.24060656424976593\n",
      "18 0.9676203482949787 0.24284339650480505\n",
      "19 0.9665196173511043 0.2479393505259485\n",
      "20 0.9655757162162828 0.2504336496396134\n"
     ]
    }
   ],
   "source": [
    "# Iterate through a range of neighborhood sizes\n",
    "for K in range(2,21):\n",
    "    # Predict ratings for each user-item pair in the test data.\n",
    "    testing_size = 0\n",
    "    error_count = 0\n",
    "    u1_pred = np.zeros((USERS,ITEMS))\n",
    "    for user in range(USERS):\n",
    "        for item in range(ITEMS):\n",
    "            if u1_test_data[user][item] == 0:\n",
    "                continue\n",
    "            try:\n",
    "                pred_val = r_hat(user, item, K)\n",
    "                u1_pred[user][item] = pred_val\n",
    "                testing_size += 1\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "            \n",
    "    count = 0\n",
    "    squared_error = 0\n",
    "\n",
    "    # calculate the RMSE for each neighborhood size\n",
    "    for user in range(USERS):\n",
    "        for item in range(ITEMS):\n",
    "            if u1_pred[user][item] == 0:\n",
    "                continue\n",
    "            squared_error += (u1_pred[user][item] - u1_test_data[user][item]) ** 2\n",
    "            count += 1\n",
    "    RMSE = math.sqrt(squared_error / count)\n",
    "\n",
    "    # calculate the average Kendall rank correlation coefficient for each neighborhood size\n",
    "    count = 0\n",
    "    total_ken = 0\n",
    "    for user in range(USERS):\n",
    "        try:\n",
    "            total_ken += user_kendall_coef(user)\n",
    "            count += 1\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "\n",
    "    print(K, RMSE, total_ken / count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b1a5b2f53fe8d0bcd4ac39533e586bc42b57972f340950c5b9dd959554a56a5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
