{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood Based Recommender Systems\n",
    "Here we implement a user-based recommender system on the MovieLens 100k Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Lens 1M\n",
    "Here we work with the Movie Lens 1M data set, because the 20M one is a bit too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up some constants\n",
    "K_FOLD = 5\n",
    "\n",
    "# numbers of users and items\n",
    "\n",
    "ITEMS = 3952\n",
    "USERS = 6040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "\n",
    "# # This function reads data from file and writes it to \n",
    "# def read_data(file, target):\n",
    "#     with open(file) as f:\n",
    "#         line = f.readline()\n",
    "#         while line:\n",
    "#             try:\n",
    "#                 user, item, rating, _ = line.split(sep='::')\n",
    "#                 target[randint(0,4)][int(user)-1, int(item)-1] = int(rating)\n",
    "#             except ValueError:\n",
    "#                 print(line)\n",
    "#             line = f.readline()\n",
    "\n",
    "# # Here we read in the ratings in ML-1M and store it in data_1m.npz\n",
    "\n",
    "# data_1m = [sparse.lil_matrix((USERS, ITEMS), dtype=np.int8) for _ in range(K_FOLD)]\n",
    "\n",
    "# read_data(\".\\\\ml-1m\\\\ratings.dat\", data_1m)\n",
    "\n",
    "# for i in range(K_FOLD):\n",
    "#     sparse.save_npz('data_1m_' + str(i) + \".npz\", data_1m[i].tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we load the presplit datasets\n",
    "data_1m = [sparse.csr_matrix((USERS, ITEMS), dtype=np.int8) for _ in range(K_FOLD)]\n",
    "\n",
    "for i in range(K_FOLD):\n",
    "    data_1m[i] = sparse.load_npz(\"data_1m_\" + str(i) + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "def get_training_set(i):\n",
    "    return sum([data_1m[k] for k in range(K_FOLD) if k != i])\n",
    "\n",
    "train_data_0 = get_training_set(0)\n",
    "test_data_0 = data_1m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average rating for each user\n",
    "\n",
    "averages = [user.sum() / user.count_nonzero() for user in train_data_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rated_items(user):\n",
    "    return set(train_data_0[user].nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay_w\\AppData\\Local\\Temp/ipykernel_15316/2249407663.py:70: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  top = np.sum(pear * (train_data_0[user2,item] - averages[user2]) for pear, user2 in K_closest_users)\n",
      "C:\\Users\\jay_w\\AppData\\Local\\Temp/ipykernel_15316/2249407663.py:71: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  bot = np.sum(abs(pear) for pear, _ in K_closest_users)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "  (0, 0)\t5.062764778825982\n",
      "  (0, 149)\t4.635955450706121\n",
      "  (0, 587)\t4.799661605317113\n",
      "  (0, 719)\t5.366736538411148\n",
      "  (0, 782)\t4.3394999604319064\n",
      "  (0, 1196)\t5.114346377065084\n",
      "  (0, 1544)\t4.374111692461498\n",
      "  (0, 2017)\t4.977497631764379\n",
      "  (0, 2027)\t4.757058659655483\n",
      "  (0, 2339)\t3.5864991351820166\n",
      "  (0, 2686)\t4.280012320510714\n",
      "  (0, 2691)\t4.899545744228838\n",
      "  (0, 2790)\t4.557414504960032\n",
      "  (0, 2796)\t4.456814464281303\n",
      "  (0, 2917)\t4.912379717923426\n",
      "  (0, 3104)\t4.12369223630969\n",
      "  (1, 291)\t3.4694555509251535\n",
      "  (1, 355)\t4.602268131241613\n",
      "  (1, 1197)\t4.673378433003522\n",
      "  (1, 1384)\t3.6487405927907894\n",
      "  (1, 1551)\t4.151628357112327\n",
      "  (1, 1596)\t4.029945929882513\n",
      "  (1, 1686)\t3.2938342026542573\n",
      "  (1, 1791)\t3.6184083292459017\n",
      "  (1, 1833)\t3.8690886303154324\n",
      "  (1, 1944)\t3.727427763374916\n",
      "  (1, 2005)\t4.432002780120445\n",
      "  (1, 2027)\t4.262977685648167\n",
      "  (1, 2267)\t4.033073207776188\n",
      "  (1, 2395)\t4.061608659538027\n",
      "  (1, 2489)\t3.9358677725780815\n",
      "  (1, 2716)\t3.203605942810455\n",
      "  (1, 2915)\t3.774062658839857\n",
      "  (1, 3146)\t4.53576199647028\n",
      "  (1, 3254)\t3.5488199299810477\n",
      "  (1, 3677)\t4.395346216592934\n",
      "  (1, 3698)\t3.854366797562209\n",
      "  (1, 3892)\t4.076817657219604\n",
      "  (2, 551)\t4.347985386647339\n",
      "  (2, 1135)\t4.766856169305103\n",
      "  (2, 1196)\t4.324787965210022\n",
      "  (2, 1258)\t4.8906213580251094\n",
      "  (2, 1260)\t4.075584130745608\n",
      "  (2, 1430)\t2.5912551095954197\n",
      "  (2, 1614)\t3.6201525020881693\n",
      "  (2, 1967)\t4.372088827108834\n",
      "  (2, 2469)\t4.404774831291413\n",
      "  (2, 3533)\t3.860141260636522\n",
      "  (3, 1209)\t4.134549215634429\n",
      "  (3, 1386)\t4.836904408904626\n",
      "  (3, 2027)\t4.250585523579125\n",
      "  (4, 31)\t4.512084586580529\n",
      "  (4, 40)\t2.786036738280771\n",
      "  (4, 161)\t3.8782249660743506\n",
      "  (4, 193)\t3.3225164113422725\n",
      "  (4, 201)\t1.4831346887150858\n",
      "  (4, 228)\t3.345735772332198\n",
      "  (4, 271)\t3.1529187208825453\n",
      "  (4, 287)\t3.8627030816587906\n",
      "  (4, 352)\t2.843898526042862\n",
      "  (4, 376)\t2.6734506334588213\n",
      "  (4, 496)\t2.9904760615935997\n",
      "  (4, 505)\t2.8997507798064013\n",
      "  (4, 508)\t2.841820287572543\n",
      "  (4, 727)\t2.3678548087259306\n",
      "  (4, 967)\t3.286195474761059\n",
      "  (4, 1045)\t3.987563510580011\n",
      "  (4, 1092)\t2.2737967092286384\n",
      "  (4, 1191)\t3.355875729348451\n",
      "  (4, 1242)\t3.704648879363845\n",
      "  (4, 1278)\t3.4945765276274274\n",
      "  (4, 1516)\t4.014359690354027\n",
      "  (4, 1526)\t2.7319344541696893\n",
      "  (4, 1553)\t2.9007084067506144\n",
      "  (4, 1642)\t3.587290619206087\n",
      "  (4, 1648)\t3.606278228802011\n",
      "  (4, 1652)\t3.8030922243212353\n",
      "  (4, 1721)\t1.9893772294975252\n",
      "  (4, 1733)\t3.1468929270812267\n",
      "  (4, 1965)\t3.4841080214791216\n",
      "  (4, 2267)\t2.822715400017797\n",
      "  (4, 2322)\t4.062813196510699\n",
      "  (4, 2332)\t3.499586321544878\n",
      "  (4, 2389)\t2.7760734051706257\n",
      "  (4, 2598)\t3.6146122171256745\n",
      "  (4, 2857)\t3.9302860344499275\n",
      "  (4, 2889)\t3.4210902986668175\n",
      "  (4, 2996)\t3.444698697562092\n",
      "  (4, 3015)\t2.904785988948727\n",
      "  (4, 3078)\t3.014008236861727\n",
      "  (4, 3623)\t3.220473442636258\n",
      "  (4, 3743)\t2.0880677766359534\n",
      "  (4, 3792)\t3.263154964261535\n",
      "  (4, 3798)\t1.98342397671196\n",
      "  (5, 376)\t4.301363483782037\n",
      "  (5, 589)\t4.56403611529122\n",
      "  (5, 596)\t4.135796210303222\n",
      "  (5, 919)\t4.622784932139523\n",
      "  (5, 1027)\t4.766898846637683\n",
      "  (5, 1187)\t4.665390193651338\n",
      "  (5, 1568)\t3.742106485196764\n",
      "  (5, 1687)\t4.121287487155096\n",
      "  (5, 1805)\t4.125871322751158\n",
      "  (5, 1946)\t4.244133789691431\n",
      "  (5, 3071)\t3.979198736454263\n",
      "  (5, 3507)\t4.034619213999836\n",
      "  (5, 3698)\t4.216591194909188\n",
      "  (5, 3716)\t3.946265384852174\n",
      "  (6, 348)\t4.27590795326925\n",
      "  (6, 376)\t4.525260599691299\n",
      "  (6, 379)\t4.54160412298909\n",
      "  (6, 456)\t4.674282832702092\n",
      "  (6, 588)\t4.974449544015939\n",
      "  (6, 732)\t4.243232487013108\n",
      "  (6, 1609)\t4.495779862014454\n",
      "  (6, 1721)\t3.8865265623377723\n",
      "  (7, 16)\t4.336852443300158\n",
      "  (7, 35)\t4.4817952409334705\n",
      "  (7, 38)\t3.5438792773148156\n",
      "  (7, 41)\t3.7693244920428217\n",
      "  (7, 57)\t4.025263145668137\n",
      "  (7, 72)\t3.092675634069767\n",
      "  (7, 149)\t4.468489452010067\n",
      "  (7, 265)\t3.2178448794367354\n",
      "  (7, 268)\t3.6084589622934224\n",
      "  (7, 336)\t4.57709311854023\n",
      "  (7, 392)\t2.564362587072681\n",
      "  (7, 507)\t3.6424666423046244\n",
      "  (7, 554)\t4.940017164119767\n",
      "  (7, 649)\t3.6365277974912216\n",
      "  (7, 1058)\t3.8965858520395935\n",
      "  (7, 1273)\t4.36637902061396\n",
      "  (7, 1410)\t4.090855691889301\n",
      "  (7, 1572)\t4.029631007898226\n",
      "  (7, 1620)\t3.30189155408726\n",
      "  (7, 1652)\t4.2886260597324\n",
      "  (7, 1710)\t3.4710482095142527\n",
      "  (7, 1729)\t3.635665854049615\n",
      "  (7, 1809)\t4.200026399849016\n",
      "  (7, 1839)\t3.650183475679068\n",
      "  (7, 2319)\t3.5931493865567328\n",
      "  (7, 2395)\t3.5480767092123062\n",
      "  (7, 2441)\t3.2689951696491413\n",
      "  (7, 2489)\t3.946511834127901\n",
      "  (7, 2570)\t5.078764895313763\n",
      "  (7, 2685)\t3.9874923673893665\n",
      "  (7, 2701)\t3.842353079980856\n",
      "  (7, 3251)\t4.516442975661755\n",
      "  (7, 3255)\t4.599593046713119\n",
      "  (7, 3256)\t3.3633420489193333\n",
      "  (7, 3258)\t3.9800795682646086\n",
      "  (7, 3499)\t3.6755383117668607\n",
      "  (8, 0)\t4.237326157867154\n",
      "  (8, 299)\t3.6971705770359016\n",
      "  (8, 348)\t3.8677224316068477\n",
      "  (8, 376)\t3.337071059183861\n",
      "  (8, 456)\t3.546950207355759\n",
      "  (8, 592)\t4.40651933462002\n",
      "  (8, 837)\t4.451468179303299\n",
      "  (8, 1209)\t4.265355555314967\n",
      "  (8, 1222)\t4.028709241252603\n",
      "  (8, 1309)\t4.543998964157543\n",
      "  (8, 1583)\t3.9693460041652724\n",
      "  (8, 1703)\t3.867309419869487\n",
      "  (8, 1776)\t4.009268347413418\n",
      "  (8, 2301)\t3.6528050252579236\n",
      "  (8, 2691)\t4.29826274390847\n",
      "  (8, 3177)\t3.7303212530602283\n",
      "  (8, 3252)\t3.3542036930124524\n",
      "  (8, 3269)\t3.863257927817621\n",
      "  (8, 3297)\t4.155747649845124\n",
      "  (8, 3300)\t2.9893792270258714\n",
      "  (8, 3716)\t2.825086212333921\n",
      "  (8, 3750)\t3.692878892027218\n",
      "  (8, 3915)\t4.7261601125947506\n",
      "  (9, 47)\t4.072954805941686\n",
      "  (9, 185)\t3.8385396257310362\n",
      "  (9, 202)\t4.58657766014942\n",
      "  (9, 252)\t3.891981133914113\n",
      "  (9, 276)\t3.729199335603678\n",
      "  (9, 315)\t4.530106566476815\n",
      "  (9, 338)\t4.180151476369206\n",
      "  (9, 350)\t4.305164692988789\n",
      "  (9, 550)\t2.6663699793730995\n",
      "  (9, 586)\t3.95133720108141\n",
      "  (9, 652)\t4.628825104209374\n",
      "  (9, 764)\t3.560468268217178\n",
      "  (9, 901)\t3.961986325355859\n",
      "  (9, 917)\t4.692920150295663\n",
      "  (9, 918)\t5.0130895040301295\n",
      "  (9, 925)\t4.774895034136488\n",
      "  (9, 952)\t5.07881290173577\n",
      "  (9, 1008)\t3.6869053073542464\n",
      "  (9, 1015)\t4.400671350397742\n",
      "  (9, 1041)\t3.2982832460711813\n",
      "  (9, 1058)\t3.851428615694873\n",
      "  (9, 1083)\t3.066468756599975\n",
      "  (9, 1103)\t3.9410727789148474\n",
      "  (9, 1123)\t4.459131991031736\n",
      "  (9, 1128)\t3.7323575704430234\n",
      "  (9, 1135)\t4.712878053691657\n",
      "  (9, 1195)\t4.530422500744996\n",
      "  (9, 1220)\t4.581721684168719\n",
      "  (9, 1222)\t5.20743605016345\n",
      "  (9, 1224)\t4.591854158861964\n",
      "  (9, 1232)\t4.906398506920145\n",
      "  (9, 1252)\t4.045415953558678\n",
      "  (9, 1408)\t4.460346196451941\n",
      "  (9, 1512)\t3.3130513346737125\n",
      "  (9, 1543)\t3.8826352897838388\n",
      "  (9, 1632)\t3.7149150254915595\n",
      "  (9, 1681)\t4.558447179298192\n",
      "  (9, 1755)\t4.547998930923755\n",
      "  (9, 2005)\t4.054941376166408\n",
      "  (9, 2008)\t4.018095732844362\n",
      "  (9, 2017)\t4.212087222581839\n",
      "  (9, 2032)\t3.6028518123703352\n",
      "  (9, 2044)\t4.552335704619566\n",
      "  (9, 2046)\t3.963948714158975\n",
      "  (9, 2048)\t4.271687665815804\n",
      "  (9, 2076)\t4.049971173737992\n",
      "  (9, 2079)\t4.402297002103952\n",
      "  (9, 2104)\t4.071277778247086\n",
      "  (9, 2108)\t4.1970967092755656\n",
      "  (9, 2110)\t2.666978127503902\n",
      "  (9, 2114)\t4.730740031973071\n",
      "  (9, 2124)\t4.575758444859354\n",
      "  (9, 2134)\t3.95299988227144\n",
      "  (9, 2320)\t3.8028105859746257\n",
      "  (9, 2335)\t4.113230069332213\n",
      "  (9, 2395)\t4.590138599823504\n",
      "  (9, 2422)\t4.184861705722349\n",
      "  (9, 2627)\t4.015210975489303\n",
      "  (9, 2761)\t3.9988093989120084\n",
      "  (9, 2794)\t5.137981251093349\n",
      "  (9, 3036)\t4.3476720217690215\n",
      "  (9, 3086)\t4.169609248729071\n",
      "  (9, 3096)\t4.598367297919273\n",
      "  (9, 3107)\t4.109884972149815\n",
      "  (9, 3480)\t5.272110849444642\n",
      "  (9, 3667)\t4.736967862922537\n",
      "  (9, 3701)\t4.305702473181566\n",
      "  (9, 3750)\t4.273951712545555\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "pearson_matrix = np.empty((USERS, USERS), dtype=np.float64)\n",
    "\n",
    "\n",
    "pred_val = sparse.lil_matrix((USERS,ITEMS))\n",
    "for user1 in range(USERS):\n",
    "    print(user1)\n",
    "    rated_items_1 = rated_items(user1)\n",
    "\n",
    "    # This implements the Pearson metric as found in equation (2.2)\n",
    "    def pearson(user1, user2, rated_items_1):\n",
    "        \n",
    "        if pearson_matrix[user1, user2] != 0.0:\n",
    "            return pearson_matrix[user1, user2]\n",
    "\n",
    "        if user1 == user2:\n",
    "            pearson_matrix[user1, user2] = 1\n",
    "            pearson_matrix[user2, user1] = 1\n",
    "            return 1\n",
    "\n",
    "        intersection = list(rated_items_1.intersection(rated_items(user2)))\n",
    "\n",
    "        if len(intersection) <= 10:\n",
    "            pearson_matrix[user1, user2] = -1\n",
    "            pearson_matrix[user2, user1] = -1\n",
    "            return -1\n",
    "\n",
    "        user1_ratings = train_data_0.getrow(user1).toarray()[0][intersection]\n",
    "        user2_ratings = train_data_0.getrow(user2).toarray()[0][intersection]\n",
    "        ones = np.ones_like(user1_ratings)\n",
    "        user1_ratings = user1_ratings - ones * averages[user1]\n",
    "        user2_ratings = user2_ratings - ones * averages[user2]\n",
    "        bottom1 = math.sqrt(np.sum(np.power(user1_ratings, 2)))\n",
    "        bottom2 = math.sqrt(np.sum(np.power(user2_ratings, 2)))\n",
    "\n",
    "        bottom1 = math.sqrt( sum([(train_data_0[user1,k] - averages[user1]) ** 2 for k in intersection]))\n",
    "        bottom2 = math.sqrt( sum([(train_data_0[user2,k] - averages[user2]) ** 2 for k in intersection]))\n",
    "\n",
    "        if bottom1 * bottom2 == 0:\n",
    "            pearson_matrix[user1, user2] = -1\n",
    "            pearson_matrix[user2, user1] = -1\n",
    "\n",
    "            return -1\n",
    "\n",
    "        top = np.dot(user1_ratings, user2_ratings)\n",
    "        pearson_val = top / (bottom1 * bottom2)\n",
    "        pearson_matrix[user1, user2] = pearson_val\n",
    "        pearson_matrix[user2, user1] = pearson_val\n",
    "        return pearson_val\n",
    "\n",
    "    for item in test_data_0[user1].nonzero()[1]:\n",
    "        rated_users = sparse.find(train_data_0.tocsc().getcol(item))[0]\n",
    "        # K_closest_users = sorted((user2 for user2 in rated_users), key=lambda x: pearson(x))[-5:]\n",
    "        \n",
    "        pearson_user = []\n",
    "\n",
    "        for user2 in rated_users:\n",
    "            pcc = pearson(user1, user2, rated_items_1)\n",
    "            if pcc >= 0:\n",
    "                \n",
    "                heapq.heappush(pearson_user, (pcc , user2))\n",
    "\n",
    "        K_closest_users = heapq.nlargest(5, pearson_user)\n",
    "        \n",
    "        if len(K_closest_users) == 0:\n",
    "            pred_val[user1, item] = averages[user1]\n",
    "            continue\n",
    "\n",
    "        top = np.sum(pear * (train_data_0[user2,item] - averages[user2]) for pear, user2 in K_closest_users)\n",
    "        bot = np.sum(abs(pear) for pear, _ in K_closest_users)\n",
    "\n",
    "        r = averages[user1] + top/bot\n",
    "\n",
    "        if r > 5:\n",
    "            r = 5\n",
    "        elif r < 0:\n",
    "            r = 0\n",
    "\n",
    "        pred_val[user1,item] = r\n",
    "print(pred_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here we read in the ratings in u1.test\n",
    "# u1_test_data = np.zeros((USERS,ITEMS))\n",
    "# read_data(\".\\\\ml-100k\\\\u1.test\", u1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE as found in equation 7.5\n",
    "# Calculated using the average ratings of each user as a baseline\n",
    "\n",
    "squared_error_avg = 0\n",
    "count = 0\n",
    "\n",
    "for user in range(USERS):\n",
    "    for item in range(ITEMS):\n",
    "        if u1_train_data[user][item] == 0:\n",
    "            continue\n",
    "        squared_error_avg += (averages[user] - u1_test_data[user][item]) ** 2\n",
    "        count += 1\n",
    "\n",
    "RMSE_avg = math.sqrt(squared_error_avg / count)\n",
    "print(RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def user_kendall_coef(user):\n",
    "    credit = 0\n",
    "    test_items = {k for k in range(ITEMS) if u1_test_data[user][k] > 0}\n",
    "\n",
    "    if len(test_items) <= 1:\n",
    "        raise ZeroDivisionError\n",
    "\n",
    "    for item1, item2 in combinations(test_items, 2):\n",
    "        val = (u1_test_data[user][item1] - u1_test_data[user][item2]) * (u1_pred[user][item1] - u1_pred[user][item2])\n",
    "        if val > 0:\n",
    "            credit += 1\n",
    "        elif val < 0:\n",
    "            credit -= 1\n",
    "    \n",
    "    return credit / (len(test_items) * (len(test_items) - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through a range of neighborhood sizes\n",
    "for K in range(2,21):\n",
    "    # Predict ratings for each user-item pair in the test data.\n",
    "    testing_size = 0\n",
    "    error_count = 0\n",
    "    u1_pred = np.zeros((USERS,ITEMS))\n",
    "    for user in range(USERS):\n",
    "        for item in range(ITEMS):\n",
    "            if u1_test_data[user][item] == 0:\n",
    "                continue\n",
    "            try:\n",
    "                pred_val = r_hat(user, item, K)\n",
    "                u1_pred[user][item] = pred_val\n",
    "                testing_size += 1\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "            \n",
    "    count = 0\n",
    "    squared_error = 0\n",
    "\n",
    "    # calculate the RMSE for each neighborhood size\n",
    "    for user in range(USERS):\n",
    "        for item in range(ITEMS):\n",
    "            if u1_pred[user][item] == 0:\n",
    "                continue\n",
    "            squared_error += (u1_pred[user][item] - u1_test_data[user][item]) ** 2\n",
    "            count += 1\n",
    "    RMSE = math.sqrt(squared_error / count)\n",
    "\n",
    "    # calculate the average Kendall rank correlation coefficient for each neighborhood size\n",
    "    count = 0\n",
    "    total_ken = 0\n",
    "    for user in range(USERS):\n",
    "        try:\n",
    "            total_ken += user_kendall_coef(user)\n",
    "            count += 1\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "\n",
    "    print(K, RMSE, total_ken / count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b1a5b2f53fe8d0bcd4ac39533e586bc42b57972f340950c5b9dd959554a56a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MLLA': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
